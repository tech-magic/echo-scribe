# ğŸ™ï¸ EchoScribe: Real-Time, Speaker-Aware Meeting Transcripts â€” No Cloud Needed, On your Local Device, and FREE! ğŸ•’ğŸ§‘â€ğŸ¤â€ğŸ§‘

> Meet ğŸ™ï¸ **EchoScribe** â€” your **free AI-powered** meeting companion! ğŸš€
It captures conversations ğŸ¤, transcribes them instantly in English ğŸ“œ, separates each speaker ğŸ§‘â€ğŸ¤â€ğŸ§‘, and saves your transcripts in **TXT** or **SRT**. All 100% free, open-source, and runs right on your own device. ğŸ’»âœ¨

By feeding your speaker-labeled meeting transcripts to ChatGPT, you unlock powerful insights and productivity boosts:
- **Summarize meetings for everyone** â€” generate clear, concise summaries for laymen or management.
- **Automatically track action items** â€” identify tasks discussed and assign responsibilities without manual effort.
- **Spot issues and solutions** â€” quickly highlight problems raised and the solutions proposed.
- **Get AI-driven guidance** â€” receive actionable answers for unresolved questions or challenges discussed in the meeting.

---

## ğŸš€ Features

- ğŸ§ **Real-time audio capture** from your microphone  
- ğŸ“ **Speech-to-text transcription** using [faster-whisper](https://github.com/guillaumekln/faster-whisper)  
- ğŸ§‘â€ğŸ¤â€ğŸ§‘ **Speaker diarization** with [SpeechBrain](https://speechbrain.github.io/)  
- ğŸ’¾ Automatic saving of transcripts in:
  - **TXT** (readable transcripts)
  - **SRT** (subtitle format with timestamps)  
- ğŸ“‚ **Session history** with downloadable past transcripts  
- ğŸŒ Beautiful **Gradio Web UI** + REST API (via FastAPI)

---

## ğŸ“¦ Installation Guide

#### ğŸ–¥ï¸ Test Environment

This program was tested using Python 3.10.16 on an Apple M1 Mac running macOS Ventura 13.7.1.

```bash
python3 --version
# Python 3.10.16

pip3 --version
# pip 23.0.1 from /Users/{your_username}/.pyenv/versions/3.10.16/lib/python3.10/site-packages/pip (python 3.10)

uname -a
# Darwin {your_machine_name} 22.6.0 Darwin Kernel Version 22.6.0: Thu Sep  5 20:47:01 PDT 2024; root:xnu-8796.141.3.708.1~1/RELEASE_ARM64_T6000 arm64

sw_vers
# ProductName:            macOS
# ProductVersion:         13.7.1
# BuildVersion:           22H221

uname -m
# arm64

sysctl -n machdep.cpu.brand_string
# Apple M1 Max
```

#### âš™ï¸ Installation Steps

```bash
# Clone this repository
git clone https://github.com/tech-magic/echo-scribe.git
cd echo-scribe

# Create your own python virtual environment
python3 -m venv echo-scribe-venv
source echo-scribe-venv/bin/activate

# Install all requirements into the python virtual environment
pip3 install -r requirements.txt

# Run the app from the python virtual environment
python3 app.py
```

Then open your browser at ğŸ‘‰ [http://localhost:7860](http://localhost:7860)

---

## ğŸ’» Web UI Preview

- **Start Recording** â–¶ï¸  
- **Stop Recording** â¹ï¸  
- **Transcript Panel** ğŸ“œ â€“ real-time streaming transcript  
- **Past Sessions** ğŸ“‚ â€“ download **TXT** / **SRT** files

---

## ğŸ·ï¸ Application Design and Overview

### Utilities

- **TimestampFormatter ğŸ•’**  
  *Formats timestamps to text.*

- **FileUtils ğŸ“**  
  *Handles file path operations.*  
  *Example:* Get relative file paths if they exist in session directories.

### Audio Components

- **AudioProducer ğŸ¤**  
  *Captures audio from the microphone.*  
  *Example:* Records sound and sends it to a queue for processing.

- **AudioConsumer ğŸ§**  
  *Reads audio chunks from the queue.*  
  *Example:* Processes audio chunks for transcription and speaker detection.

- **AudioQueue ğŸ”„**  
  *Acts as a buffer between producer and consumer.*  
  *Example:* Stores audio chunks temporarily for consumption.

### AI Components

- **SpeechToText ğŸ“**  
  *Transcribes audio to text.*  
  *Example:* Uses FastWhisper to convert speech into readable text.

- **SpeakerDiarizer ğŸ­**  
  *Differentiates between speakers in audio.*  
  *Example:* Assigns speaker IDs and tracks who is speaking when.

### Recording Components

- **TranscriptWriter ğŸ“œ**  
  *Writes transcripts to text and SRT files.*  
  *Example:* Generates formatted transcript files with timestamps and speaker labels.

- **SessionManager ğŸ—‚ï¸**  
  *Manages session directories and stored files.*  
  *Example:* Keeps track of multiple recording sessions and file organization.

### Coordinator

- **TranscriptionPipeline ğŸš€**  
  *Orchestrates the whole transcription workflow.*  
  *Example:* Coordinates audio capture, processing, transcription, diarization, and writing.

### Class Diagram

```mermaid
classDiagram
    %% =======================
    %% Utilities
    %% =======================
    class TimestampFormatter {
        +format(seconds: float, srt: bool) string
    }

    class FileUtils {
        +get_relative_if_exists(session_path: str, filename: str) string
    }

    %% =======================
    %% Audio Components
    %% =======================
    class AudioProducer {
        +queue
        +sample_rate
        +callback(indata, frames, time, status)
        +record_stream()
    }

    note for AudioProducer "Captures audio from local microphone<br/>(using python sounddevice library)"

    class AudioConsumer {
        +queue
        +sample_rate
        +chunk_duration
        +overlap_duration
        +audio_buffer
        +total_audio_time
        +get_next_chunk() tuple
    }

    class AudioQueue {
    }

    %% =======================
    %% AI Components
    %% =======================
    class SpeechToText {
        +model
        +transcribe(audio_np: np.ndarray)
    }

    note for SpeechToText "Transcribes audio to text using fastwhisper<br/>(optimized OpenAI's Whisper model)"

    class SpeakerDiarizer {
        +spkrec
        +speakers
        +next_speaker_id
        +similarity_threshold
        +_get_embedding(chunk: np.ndarray)
        +get_label(chunk: np.ndarray, start_time: float) string
    }

    note for SpeakerDiarizer "Differentiates different speakers<br/>(using speechbrain)"

    class TranscriptWriter {
        +txt_file
        +srt_file
        +srt_index
        +write(start, end, speaker, text) string
        +close()
    }

    class SessionManager {
        +base_dir
        +list_sessions() list
    }

    %% =======================
    %% Coordinator
    %% =======================
    class TranscriptionPipeline {
        +producer
        +consumer
        +stt
        +diarizer
        +writer
        +executor
        +stop_event
        +transcript_lines
        +process_chunk(chunk, chunk_start_time)
        +run()
    }

    %% =======================
    %% Relationships
    %% =======================
    TranscriptionPipeline --> AudioProducer : uses
    TranscriptionPipeline --> AudioConsumer : uses
    TranscriptionPipeline --> SpeechToText : uses
    TranscriptionPipeline --> SpeakerDiarizer : uses
    TranscriptionPipeline --> TranscriptWriter : writes

    AudioProducer --> AudioQueue : produces_audio_for
    AudioConsumer --> AudioQueue : consumes_audio_from
    TranscriptWriter --> SessionManager : stores_sessions_in
    TranscriptWriter --> TimestampFormatter : uses
    SessionManager --> FileUtils : uses
```

---

## ğŸ“‚ Session Management

All recordings (during each captured session) are saved under the `data/` directory:

```
data/
 â”œâ”€â”€ 01-09-2025-20-15-45/
 â”‚   â”œâ”€â”€ 01-09-2025-20-15-45_transcript.txt
 â”‚   â””â”€â”€ 01-09-2025-20-15-45_subtitles.srt
 â”œâ”€â”€ 01-09-2025-21-00-12/
 â”‚   â”œâ”€â”€ 01-09-2025-21-00-12_transcript.txt
 â”‚   â””â”€â”€ 01-09-2025-21-00-12_subtitles.srt
```

---

## ğŸ”Œ API Endpoints

EchoScribe also provides REST endpoints via **FastAPI**:

- **Download transcript/subtitles files:**  
  ```
  GET /data/{session_id}/{filename}
  ```

Example:

```bash
curl http://localhost:7860/data/01-09-2025-20-15-45/01-09-2025-20-15-45_transcript.srt -o 01-09-2025-20-15-45_transcript.srt
```

---

## âš™ï¸ Tech Stack

- [Gradio](https://www.gradio.app/) â€“ Web UI  
- [FastAPI](https://fastapi.tiangolo.com/) â€“ REST API  
- [faster-whisper](https://github.com/guillaumekln/faster-whisper) â€“ ASR engine  
- [SpeechBrain](https://speechbrain.github.io/) â€“ Speaker recognition  
- [PyTorch](https://pytorch.org/) â€“ Deep learning backend  
- [scikit-learn](https://scikit-learn.org/) â€“ Similarity metrics  

---

## âœ¨ Further Improvements

- [ ] Multi-language transcription ğŸŒ  
- [ ] Pre-trained speaker labeling (e.g., "Alice", "Bob") ğŸ·ï¸  


---

## ğŸ“œ License

MIT License Â© 2025

---

Happy **Transcribing**! ğŸš€